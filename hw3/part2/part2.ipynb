{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate a video for the course of \"Application of Deep Learning\"\n",
        "Code was generated by ChatGPT 4o (Aug. 6, 2024)"
      ],
      "metadata": {
        "id": "D7JmVzbA3CLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3OPPK5k4e4R",
        "outputId": "7d980484-aff7-42fd-d016-51c7880ba093"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gtts) (2.32.4)\n",
            "Collecting click<8.2,>=7.1 (from gtts)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gtts) (2025.8.3)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gtts\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed click-8.1.8 gtts-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "naJM92Oa2-SK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "d87b1fa6-47d4-4153-c302-f7af23caac17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video ./class_exercise.mp4.\n",
            "MoviePy - Writing audio in class_exerciseTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video ./class_exercise.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready ./class_exercise.mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./class_exercise.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import moviepy.editor as mp\n",
        "import gtts\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# List of images and their respective durations in seconds\n",
        "images = [\n",
        "    (\"./data/image1.jpeg\", 6),\n",
        "    (\"./data/image2.jpeg\", 4),\n",
        "    (\"./data/image3.jpeg\", 7)\n",
        "]\n",
        "\n",
        "# Corresponding voiceover text for each image\n",
        "voiceover_texts = [\n",
        "    \"students are learning the course application of deep learing in SB-G24\",\n",
        "    \"teacher asks students to work on in-class exercise\",\n",
        "    \"many students finish the in-class exercise successfully and get 0.1 extra credits!\"\n",
        "]\n",
        "\n",
        "# Function to add text to an image with multiple lines and blue text color\n",
        "def add_text_to_image_multiline_black(image_path, text, output_path, font_size=40, max_width=50, y_offset=400):\n",
        "    img = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    font = ImageFont.truetype(\"LiberationSans-Bold.ttf\", font_size)\n",
        "\n",
        "    # Split the text into multiple lines\n",
        "    lines = []\n",
        "    words = text.split()\n",
        "    while words:\n",
        "        line = ''\n",
        "        while words and len(line) + len(words[0]) + 1 <= max_width:\n",
        "            line = line + (words.pop(0) + ' ')\n",
        "        lines.append(line.strip())\n",
        "\n",
        "    # Calculate text position\n",
        "    total_text_height = sum([draw.textbbox((0, 0), line, font=font)[3] - draw.textbbox((0, 0), line, font=font)[1] for line in lines])\n",
        "    width, height = img.size\n",
        "    y = (height - total_text_height) / 2 + y_offset\n",
        "\n",
        "    for line in lines:\n",
        "        text_w = draw.textlength(line, font=font)\n",
        "        text_h = draw.textbbox((0, 0), line, font=font)[3] - draw.textbbox((0, 0), line, font=font)[1]\n",
        "        x = (width - text_w) / 2\n",
        "        draw.rectangle([(x - 10, y - 10), (x + text_w + 10, y + text_h + 10)], fill=\"black\")\n",
        "        draw.text((x, y), line, font=font, fill=\"white\")\n",
        "        y += text_h * 2\n",
        "\n",
        "    img.save(output_path)\n",
        "\n",
        "# Add captions to images using default font\n",
        "captioned_images = []\n",
        "for i, (image_path, duration) in enumerate(images):\n",
        "    output_path = f\"./data/captioned_image_{i}.png\"\n",
        "    add_text_to_image_multiline_black(image_path, voiceover_texts[i], output_path)\n",
        "    captioned_images.append((output_path, duration))\n",
        "\n",
        "# Generate voiceover using gTTS\n",
        "voiceover_clips = []\n",
        "for i, text in enumerate(voiceover_texts):\n",
        "    tts = gtts.gTTS(text, lang='en')\n",
        "    tts.save(f\"./data/voiceover_{i}.mp3\")\n",
        "    voiceover_clips.append(mp.AudioFileClip(f\"./data/voiceover_{i}.mp3\"))\n",
        "\n",
        "# Create a video clip for each image\n",
        "image_clips = []\n",
        "for i, (image_path, duration) in enumerate(captioned_images):\n",
        "    img_clip = mp.ImageClip(image_path).set_duration(duration)\n",
        "    img_clip = img_clip.set_audio(voiceover_clips[i])\n",
        "    image_clips.append(img_clip)\n",
        "\n",
        "# Concatenate all image clips into one video\n",
        "final_clip = mp.concatenate_videoclips(image_clips)\n",
        "\n",
        "# Write the final video to a file\n",
        "output_file_path = \"./class_exercise.mp4\"\n",
        "final_clip.write_videofile(output_file_path, fps=24)\n",
        "\n",
        "output_file_path"
      ]
    }
  ]
}